{
  "master": {
    "tasks": [
      {
        "id": 28,
        "title": "Define and Implement Agent Configuration JSON Schema",
        "description": "Create and implement a JSON Schema to validate the YAML front-matter of agent definition files. This ensures all agent configurations are well-formed and contain the required fields like name, description, tools, and keywords.",
        "details": "The schema must validate fields specified in the PRD: `name`, `description`, `model` (optional), `tools` (array of strings), `priority`, and `keywords` (array of strings). Use a library like 'ajv' for validation.",
        "testStrategy": "Create unit tests with valid and invalid YAML front-matter examples to ensure the schema validation works correctly, catching missing fields, incorrect data types, and other constraint violations.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 29,
        "title": "Implement Agent File Discovery and Parser",
        "description": "Develop the mechanism to discover agent definition files from both project-specific (`.pk/agents/`) and user-global (`~/.pk/agents/`) directories. This includes parsing the Markdown files, extracting the YAML front-matter, and validating it.",
        "details": "The system should handle name collisions by prioritizing project-specific agents over global ones. Use a library like 'js-yaml' for parsing. Gracefully handle errors for malformed files.",
        "testStrategy": "Test file discovery from both locations, correct parsing of valid files, and proper error logging for invalid or unparseable files. Verify the project-over-global priority logic.",
        "priority": "high",
        "dependencies": [
          28
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 30,
        "title": "Implement Hot-Reloading for Agent Definitions",
        "description": "Enable the system to dynamically detect changes (creation, modification, deletion) in agent definition files and update the available agents in memory without requiring a CLI restart.",
        "details": "Use a file system watcher to monitor the agent directories. Ensure the reloading process is efficient and handles updates, additions, and removals of agent configurations correctly.",
        "testStrategy": "Run the CLI and, in a separate process, add, modify, and delete agent files. Verify that the CLI reflects these changes in real-time when listing or using agents.",
        "priority": "medium",
        "dependencies": [
          29
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 31,
        "title": "Develop Keyword-Based Routing Engine",
        "description": "Implement the initial routing logic that delegates an incoming user query to the most appropriate agent based on matching keywords defined in the agent's front-matter.",
        "details": "The engine should parse the user's prompt and compare it against the `keywords` array of all loaded agents. It should also respect the `priority` field for tie-breaking. A fallback to a default agent must be implemented if no match is found.",
        "testStrategy": "Create a test suite of sample prompts designed to trigger specific agents. Measure the delegation accuracy against a predefined set of correct outcomes. The target is ≥80% accuracy.",
        "priority": "high",
        "dependencies": [
          29
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 32,
        "title": "Implement Explicit Agent Invocation Syntax",
        "description": "Add support for the `pk use <agent>: \"<query>\"` command syntax, allowing users to bypass the automatic routing and explicitly invoke a specific agent by name.",
        "details": "This requires parsing the new command structure in the CLI. The system should look up the agent by its `name` and execute it with the provided query. Handle cases where the specified agent does not exist.",
        "testStrategy": "Write end-to-end tests for the CLI, invoking known agents with sample queries and verifying the correct agent is executed. Test error handling for non-existent agent names.",
        "priority": "high",
        "dependencies": [
          29
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 33,
        "title": "Build the Parallel Execution Engine",
        "description": "Create the core engine that can execute multiple agents concurrently. The foundational architecture is in place, but requires debugging and completion of key integration points.",
        "status": "done",
        "dependencies": [
          32
        ],
        "priority": "high",
        "details": "The engine is built around an `AgentExecutor` class (85% complete) supporting parallel, sequential, and prioritized execution. It integrates with a well-designed `AgentOrchestrator` (90% complete) and an `AgentRouter` (70% complete). Key features include timeout/error handling, resource management, and performance monitoring. Current focus is on fixing the agent router, implementing the `ResultAggregator`, and integrating the content generator.",
        "testStrategy": "First, resolve the comprehensive but currently failing test suite, particularly the 9 tests related to the agent router's scoring algorithm. Once all tests pass, conduct the benchmark by invoking 3-4 agents in parallel. Measure total wall-clock time against sequential execution to validate performance gains and ensure the overhead remains ≤400ms.",
        "subtasks": [
          {
            "id": 1,
            "title": "Fix agent router scoring algorithm to pass all 9 failing tests",
            "description": "",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement the ResultAggregator based on the defined interface",
            "description": "",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Complete the Content Generator factory integration",
            "description": "",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Resolve all failing tests to validate functionality",
            "description": "",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Benchmark performance against the ≤400ms overhead target",
            "description": "",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 34,
        "title": "Implement Timeout Handling and Result Aggregation",
        "description": "Enhance the parallel executor with timeout handling for hung agent processes and a mechanism to aggregate results from all completed agents into a structured output.",
        "details": "Use `AbortController` to implement timeouts. Design a structured JSON or Markdown format for the aggregated results, clearly indicating which agent produced each part of the output.",
        "testStrategy": "Test the timeout mechanism by simulating a non-responsive agent. Test the aggregation by running multiple agents and verifying the final output is correctly structured and contains all results.",
        "priority": "high",
        "dependencies": [
          33
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 35,
        "title": "Implement Per-Agent Tool Sandboxing",
        "description": "Enforce tool permissions on a per-agent basis by restricting each agent to only the tools specified in its `tools` whitelist in the configuration file.",
        "details": "Integrate with the existing tool permission system. Before an agent executes a tool, verify that the tool is present in its configuration's `tools` array. Block any unauthorized tool usage and log the attempt.",
        "testStrategy": "Create an agent with a limited tool whitelist. Write tests that attempt to use both allowed and disallowed tools. Verify that allowed tools execute successfully and disallowed tools are blocked with an error.",
        "priority": "high",
        "dependencies": [
          29,
          33
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 36,
        "title": "Create Comprehensive Audit Logging System",
        "description": "Implement a logging system that creates a complete audit trail of all agent actions, including which agent was invoked, the query it received, the tools it used, and the final output.",
        "details": "Logs should be structured and easily parsable (e.g., JSON format). The audit trail is critical for compliance, debugging, and monitoring agent behavior.",
        "testStrategy": "Run a series of agent tasks (single, parallel, explicit) and inspect the generated audit logs to ensure they are complete, accurate, and contain all required information.",
        "priority": "high",
        "dependencies": [
          33
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 37,
        "title": "Implement Provider Fallback Mechanism",
        "description": "Build a resilience mechanism that allows the system to automatically retry a failed API call with an alternate LLM provider from a configurable list.",
        "details": "This should handle provider-specific errors like rate limits, network issues, or API downtime. The fallback chain and retry policies (e.g., number of retries, backoff strategy) should be configurable.",
        "testStrategy": "Simulate API failures from a primary provider using mocks. Verify that the system automatically retries the request with the configured secondary provider and successfully completes the task.",
        "priority": "medium",
        "dependencies": [
          33
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 38,
        "title": "Develop CLI Commands for Agent Management",
        "description": "Create new CLI commands to improve developer experience, such as `pk list-agents` to display all available agents and their descriptions.",
        "details": "The `list-agents` command should show agents from both project and global scopes, perhaps indicating their origin. Other potential commands could include `pk create-agent` from a template.",
        "testStrategy": "Execute the new CLI commands and verify their output is correct and well-formatted. Test with no agents, one agent, and multiple agents in both scopes.",
        "priority": "medium",
        "dependencies": [
          29
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 39,
        "title": "Write User Documentation and 'Hello World' Agent Tutorial",
        "description": "Create comprehensive documentation for the sub-agent system, including how to create, configure, and use custom agents. A 'Hello World' example is essential for user onboarding.",
        "details": "The documentation should cover the agent configuration schema, routing logic, parallel execution, and CLI commands. The goal is to enable a user to create and deploy a custom agent in under 5 minutes.",
        "testStrategy": "Have a new user follow the documentation to create and run a custom agent. Measure the time taken and collect feedback to ensure clarity and ease of use. Target onboarding time is <5 minutes.",
        "priority": "medium",
        "dependencies": [
          28,
          32,
          38
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 40,
        "title": "Create Test Suite for Delegation Accuracy",
        "description": "Build a dedicated test suite of at least 50 sample prompts to rigorously measure and tune the accuracy of the keyword-based routing engine.",
        "details": "The test suite should cover a wide range of domains (testing, documentation, security, general). Each prompt will have a predefined 'correct' agent. The suite will be used to validate the ≥80% accuracy success metric.",
        "testStrategy": "Run the test suite against the routing engine and automatically calculate the accuracy score. Use the results to identify weaknesses and refine the routing heuristics or keyword sets.",
        "priority": "medium",
        "dependencies": [
          31
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 41,
        "title": "Integrate Worker Threads for CPU-Intensive Tasks",
        "description": "Conditionally integrate worker threads for agents that may perform CPU-intensive tasks, preventing them from blocking the main event loop.",
        "details": "This is a conditional requirement based on performance analysis. If certain agent tasks (e.g., large data processing) are found to be CPU-bound, they should be offloaded to a worker thread.",
        "testStrategy": "Identify or create a CPU-bound task for an agent. Benchmark its execution with and without a worker thread to prove it no longer blocks other concurrent operations.",
        "priority": "low",
        "dependencies": [
          33
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 42,
        "title": "Final MVP Integration and Release Preparation",
        "description": "Integrate all core components (Agent Loader, Routing, Parallel Executor, Sandboxing, Logging) into the main PK-Code CLI application and prepare for a public beta release.",
        "details": "This task involves final end-to-end testing, code cleanup, and ensuring all MVP success criteria are met. This includes agent definition loading, keyword routing, parallel execution, tool permissions, and audit logging.",
        "testStrategy": "Perform a full regression test of the entire PK-Code application. Conduct an internal beta test with team members to gather final feedback before the public release.",
        "priority": "high",
        "dependencies": [
          34,
          35,
          36,
          39
        ],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-07-26T18:17:50.719Z",
      "updated": "2025-07-27T04:53:32.559Z",
      "description": "Tasks for master context"
    }
  }
}